import torch

# --- File Paths ---
# Assumes you have downloaded and placed the files in the data/ directory
DATA_DIR = "data/"
REF_GENOME = f"{DATA_DIR}/reference.fasta"
BAM_FILE = f"{DATA_DIR}/HG002_PacBio-HiFi-Revio_20231031_48x_GRCh38-GIABv3.bam"

# Ground Truth Files (GIAB)
TRUTH_VCF = f"{DATA_DIR}/HG002_SVs_Tier1_v0.6.vcf.gz"
TRUTH_BED = f"{DATA_DIR}/HG002_SVs_Tier1_v0.6.bed"

# Candidate VCFs from different callers
CANDIDATE_VCF_DIR = f"{DATA_DIR}/candidate_vcfs/"
CANDIDATE_VCFS = {
    "sniffles2": f"{CANDIDATE_VCF_DIR}/sniffles2.vcf",
    "pbsv": f"{CANDIDATE_VCF_DIR}/pbsv.vcf",
    "svim": f"{CANDIDATE_VCF_DIR}/svim.vcf",
    "cutesv": f"{CANDIDATE_VCF_DIR}/cutesv.vcf",
}

# --- Preprocessing ---
# This file will be generated by preprocess.py and used by dataset.py
PROCESSED_DATA_TSV = f"{DATA_DIR}/processed_sv_data.tsv"
FLANKING_SIZE = 5000  # 5kb flanking region on each side of the SV
MIN_SV_LENGTH = 50
MAX_SV_LENGTH = 50000
RECIPROCAL_OVERLAP = 0.7 # For matching candidate SVs to truth SVs

# --- Assembly ---
ASSEMBLY_DIR = "data/assembly_temp"

# --- Model & Tokenizer ---
MODEL_NAME = "zhihan1996/DNABERT-2-117M"
MAX_TOKEN_LENGTH = 1024  # Max sequence length for the model

# --- Training ---
OUTPUT_DIR = "outputs/"
MODEL_SAVE_PATH = f"{OUTPUT_DIR}/dnabert_sv_classifier.pth"
LOG_DIR = f"{OUTPUT_DIR}/logs/"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 8
EPOCHS = 5
LEARNING_RATE = 2e-5
WEIGHT_DECAY = 0.01
VALIDATION_SPLIT = 0.15 # Use 15% of data for validation

# --- Prediction ---
PREDICTION_OUTPUT_VCF = f"{OUTPUT_DIR}/predictions.vcf"